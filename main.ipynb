{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/24 13:45:01 WARN Utils: Your hostname, fossa-dsa-001 resolves to a loopback address: 127.0.1.1; using 192.168.0.111 instead (on interface wlp3s0)\n",
      "22/06/24 13:45:01 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/fossa/deb/tests/spark_fun/venv/lib/python3.7/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "22/06/24 13:45:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\"\"\"make an instance of a SparkSession called 'spark'.\"\"\"\n",
    "spark = SparkSession.builder.master('local').getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql.types import LongType, StringType, StructField, StructType, BooleanType, ArrayType, IntegerType\n",
    "\n",
    "# custom_schema = StructType([\n",
    "#     StructField('index', IntegerType()),\n",
    "#     StructField('artist_popularity', LongType()),\n",
    "#     StructField('followers', LongType()),\n",
    "#     StructField('genres', StringType()),\n",
    "#     StructField('id', StringType()),\n",
    "#     StructField('name', StringType()),\n",
    "#     StructField('track_id', StringType()),\n",
    "#     StructField('track_name_prev', StringType()),\n",
    "#     StructField('type', StringType())])\n",
    "# Read the Spotify artists CSV file into a Spark DataFrame\n",
    "spark_df = (spark.read.format(\"csv\"\n",
    "                        ).options(header=\"true\"\n",
    "                        ).schema(\"index int, artist_popularity int, followers int, genres string, id string, name string, track_id string, track_name_prev string, type string\"\n",
    "                        ).load(\"data/spotify_artists.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'artist_popularity',\n",
       " 'followers',\n",
       " 'genres',\n",
       " 'id',\n",
       " 'name',\n",
       " 'track_id',\n",
       " 'track_name_prev',\n",
       " 'type']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "spark_df.withColumnRenamed('', 'index').columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.describe of DataFrame[index: int, artist_popularity: int, followers: int, genres: string, id: string, name: string, track_id: string, track_name_prev: string, type: string]>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Profile the Data:\"\"\"\n",
    "# Show a description (summary) of the Spark DataFrame.\n",
    "spark_df.describe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: integer (nullable = true)\n",
      " |-- artist_popularity: integer (nullable = true)\n",
      " |-- followers: integer (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- track_id: string (nullable = true)\n",
      " |-- track_name_prev: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the schema of the DataFrame.\n",
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                name|              genres|\n",
      "+--------------------+--------------------+\n",
      "|       Juliano Cezar|['sertanejo', 'se...|\n",
      "|      The Grenadines|                  []|\n",
      "|             Gangway| ['danish pop rock']|\n",
      "|               FADES|['uk alternative ...|\n",
      "| Jean-Pierre Guignon|  ['french baroque']|\n",
      "|              Filhos|                  []|\n",
      "|                Eloq|                  []|\n",
      "|              Fravær|                  []|\n",
      "|       Camille Pépin|                  []|\n",
      "|Pepe Willberg & T...|['classic finnish...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select and show just the first 10 values in the 'name' and 'genres' columns.\n",
    "spark_df.select('name', 'genres').show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Clean the Data:'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Clean the Data:\"\"\"\n",
    "\n",
    "\n",
    "# Sort the data in descending order by number of followers.\n",
    "# 'artist_popularity' is a rank out of 100. Write a user defined function that will divide each popularity value by 100. Rename the column 'popularity_percent'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                name|              genres|\n",
      "+--------------------+--------------------+\n",
      "|       Juliano Cezar|['sertanejo', 'se...|\n",
      "|      The Grenadines|      elevator_music|\n",
      "|             Gangway| ['danish pop rock']|\n",
      "|               FADES|['uk alternative ...|\n",
      "| Jean-Pierre Guignon|  ['french baroque']|\n",
      "|              Filhos|      elevator_music|\n",
      "|                Eloq|      elevator_music|\n",
      "|              Fravær|      elevator_music|\n",
      "|       Camille Pépin|      elevator_music|\n",
      "|Pepe Willberg & T...|['classic finnish...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_replace\n",
    "# Where the genre is an empty list, replace it with ['elevator music'].\n",
    "spark_df = spark_df.withColumn('genres', regexp_replace(\n",
    "    'genres', r\"\\[\\]\", \"['elevator music']\"))\n",
    "spark_df.select('name', 'genres').show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the columns 'artist_popularity' and 'followers', cast the data type as integers.\n",
    "\"\"\"done in the schema\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the data in descending order by number of followers.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8793d36fc6f82970c1c1d8f760fcf31a9b83e2b77c85ced74640d867ec7076d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
